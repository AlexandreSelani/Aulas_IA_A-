# -*- coding: utf-8 -*-
"""OPF_IDS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nU735Gr6IF8dBcVssKsZHGRu20xREDUW
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install opfython pandas numpy scikit-learn matplotlib

import pandas as pd
import numpy as np
from sklearn.preprocessing import TargetEncoder,LabelEncoder,OneHotEncoder
from sklearn.model_selection import KFold,StratifiedKFold
from opfython.models import SupervisedOPF
import opfython.math.general as opf_g
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,ConfusionMatrixDisplay
import time
import matplotlib.pyplot as plt
import os
np.seterr(all='ignore')

"""##ANALISE DO KDD-CUP"""

from sklearn.datasets import fetch_kddcup99

data = fetch_kddcup99(as_frame=True, percent10=True)
df = data.frame



duplicates = df.duplicated()
print(duplicates.sum(), len(df), len(df)-duplicates.sum())

df.drop_duplicates(inplace=True)
df.head()

df["protocol_type"].value_counts()

df["service"].value_counts()

df["flag"].value_counts()

df["land"].value_counts()

df["logged_in"].value_counts()

df["is_host_login"].value_counts()

df["is_guest_login"].value_counts()

"""##PRÉ PROCESSAMENTO KDD-CUP

O dataset KDD-CUP consiste em dados de pacotes de dados que podem ou não representar ataques a uma rede.

A versão utilizada no artigo foi uma versão reduzida, com 10% das amostras. Cada amostra possui 41 features além de um rótulo que pode pertencer a 23 classes (22 representam ataques e 1 representa pacotes normais).

Conforme o texto, foram utilizadas as seguintes variantes do conjunto de dados:

*   KddCup-5:  6 classes (back DoS,buffer overflow, ftp write, guess passwd, imap e normal);
*   KddCup-10: 11 classes (ipsweep, land DoS, loadmodule, multihop, neptune, além das classes em KddCup-5)
*   KddCup-15: 16 classes (nmap, perl, phf, pod DoS, portsweep, além das classes em KddCup-10)

As features categóricas foram tratadas com One-Hot Encoder e todas as features foram padronizadas com StandardScaler.
"""

kddCup_5_classes = [b"back.",b"ftp_write.",b"buffer_overflow.",b"guess_passwd.",b"imap.",b"normal."]
kddCup5_mask = df["labels"].isin(kddCup_5_classes)
kddCup5 = df[kddCup5_mask]
kddCup5["labels"].value_counts()

kddCup_10_classes = [
    b"back.",
    b"ftp_write.",
    b"buffer_overflow.",
    b"guess_passwd.",
    b"imap.",
    b"ipsweep.",
    b"land.",
    b"loadmodule.",
    b"neptune.",
    b"multihop.",
    b"normal."
]

kddCup10_mask = df["labels"].isin(kddCup_10_classes)
kddCup10 = df[kddCup10_mask]
kddCup10["labels"].value_counts()

kddCup_15_classes = [b"back.",b"ftp_write.",b"buffer_overflow.",b"guess_passwd.",b"imap.",b"ipsweep.",b"land.",b"loadmodule.",b"neptune.",b"multihop.",b"normal.",b"nmap.",b"perl.",b"phf.",b"pod.",b"portsweep."]
kddCup15_mask = df["labels"].isin(kddCup_15_classes)
kddCup15 = df[kddCup15_mask]
kddCup15["labels"].value_counts()

"""Em todas as variantes, percebe-se o imenso desbalanceamento entre as classes. No entanto, o artigo não busca formas de tratar esse desbalanceamento. Ao invés disso, utiliza métricas que levam em consideração o desbalanceamento das classes para avaliar o modelo.

##TREINAMENTO KDD-CUP
"""

def kdd_preprocessing(dataset):
  """
  Pre-processamento do dataset kddcup
  """
  X = dataset.iloc[:,:-1]
  y = dataset.iloc[:,-1]

  X = pd.get_dummies(X, columns=["service","protocol_type", "flag"], dtype=float)
  label_encoder = LabelEncoder()
  y = pd.Series(label_encoder.fit_transform(y))

  return X,y,label_encoder

def cria_folds(X):
  """
  Separa os folds de treino e teste. Ao total serao 20 folds. 10 para treino, 10 para teste
  """
  kfold = KFold(n_splits=20)

  folds = list(kfold.split(X))

  rng = np.random.default_rng(42)  # random para garantir repetibilidade

  # escolher 10 folds aleatórios para treino
  train_folds_idx = rng.choice(20, size=10, replace=False)
  # os restantes são teste
  test_folds_idx = [i for i in range(20) if i not in train_folds_idx]


  return train_folds_idx,test_folds_idx,folds

def cross_validation_knn(X,y,params):
  """Recebe um fold de treino e os parâmetros a serem testados. Retorna os parametros com melhor media de opf-style accuracy"""
  SKFold = KFold(n_splits=5)

  K_avg_accs = []

  max_label_global = np.max(y)

  for k in params["K"]:
    K_accs = []

    for i, (train_idxs,val_idxs) in enumerate(SKFold.split(X,y)):
      print(f"K = {k}, fold {i}")

      X_train, X_val = X[train_idxs],X[val_idxs]
      y_train, y_val = y[train_idxs],y[val_idxs]


      knn = KNeighborsClassifier(n_neighbors=k)
      knn.fit(X_train,y_train)
      predicts = knn.predict(X_val)

      #ajuste necessario pois o fold de validacao pode contar com menos classes do que os de treino.
      #isso pode acontecer porque ha classes com poucas amostras
      y_val_calc = y_val
      predicts_calc = predicts

      if np.max(y_val) < max_label_global:
          y_val_calc = np.append(y_val, max_label_global)
          predicts_calc = np.append(predicts, max_label_global)

      opf_acc = opf_g.opf_accuracy(y_val_calc, predicts_calc)
      #print(f"opf_acc = {opf_acc}")
      K_accs.append(opf_acc)

    mean = np.array(K_accs).mean()
    print(f"media para k={k}: {mean}")

    K_avg_accs.append(mean)

  melhor_K = np.array(K_avg_accs).argmax()
  print(f"Melhor k = {params['K'][melhor_K]}")

  return params["K"][melhor_K]

def cross_validation_svm(X, y, params):
    """Recebe um fold de treino e os parâmetros a serem testados. Retorna os parametros com melhor media de opf-style accuracy"""
    SKFold = KFold(n_splits=5)

    # Matriz de médias: linhas = Cs, colunas = gammas
    C_gamma_avg_accs = np.zeros((len(params["C"]), len(params["gamma"])))

    max_label_global = np.max(y)
    for i_c, C_value in enumerate(params["C"]):
        for j_g, gamma_value in enumerate(params["gamma"]):

            gamma_accs = []

            for fold, (train_idx, val_idx) in enumerate(SKFold.split(X, y)):
                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y[train_idx], y[val_idx]

                svm = SVC(kernel="rbf", gamma=gamma_value, C=C_value)
                svm.fit(X_train, y_train)
                predicts = svm.predict(X_val)

                #ajuste necessario pois o fold de validacao pode contar com menos classes do que os de treino.
                #isso pode acontecer porque ha classes com poucas amostras
                y_val_calc = y_val
                predicts_calc = predicts

                if np.max(y_val) < max_label_global:
                    y_val_calc = np.append(y_val, max_label_global)
                    predicts_calc = np.append(predicts, max_label_global)

                opf_acc = opf_g.opf_accuracy(y_val_calc, predicts_calc)

                gamma_accs.append(opf_acc)

            C_gamma_avg_accs[i_c, j_g] = np.mean(gamma_accs)
            print(f"C={C_value}, gamma={gamma_value}, média = {C_gamma_avg_accs[i_c, j_g]}")

    # encontra o melhor índice (C, gamma)
    best_idx = np.unravel_index(np.argmax(C_gamma_avg_accs), C_gamma_avg_accs.shape)
    best_C = params["C"][best_idx[0]]
    best_gamma = params["gamma"][best_idx[1]]

    print(f"\nMelhor combinação: C={best_C}, gamma={best_gamma}")
    return best_C, best_gamma

def treinar(modelo,nome_do_modelo,X_train,y_train):
    """Treina o modelo e conta o tempo que levou"""
    tempo_inicial = time.perf_counter()
    modelo.fit(X_train,y_train)
    tempo_final = time.perf_counter()
    tempo_decorrido = tempo_final - tempo_inicial
    print(f"Tempo de treino {nome_do_modelo}: {tempo_decorrido:3f}s")
    return tempo_decorrido

def testar(modelo,nome_do_modelo,X_test):
    """Testa o modelo e conta o tempo que levou"""
    tempo_inicial = time.perf_counter()
    predicts = modelo.predict(X_test)
    tempo_final = time.perf_counter()
    tempo_decorrido = tempo_final - tempo_inicial
    print(f"Tempo de treino {nome_do_modelo}: {tempo_decorrido:3f}s")
    return tempo_decorrido,predicts

def matriz_de_confusao(cm, display_labels, dir, nome):
    os.makedirs(dir, exist_ok=True)

    n_classes = cm.shape[0]
    fig_size = max(6, n_classes * 0.7)

    fig, ax = plt.subplots(figsize=(fig_size, fig_size))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)
    disp.plot(ax=ax, xticks_rotation='vertical', colorbar=True)

    ax.set_title(nome)

    plt.tight_layout()
    plt.savefig(f"{dir}/{nome}.png", dpi=300)
    plt.close()

def kdd_experiment(dataset,dataset_name):

  #inicializacao dos parametros de grid search
  knn_cv_params = {"K":[3,5,7,9,11]}

  svm_cv_params = {"gamma":[0.001, 0.01, 0.1],
                   "C":[0.1, 1, 10]
                   }

  #inicializacao dos vetores de metricas
  all_acc_opf_opf = np.array([])
  all_acc_opf = np.array([])
  all_tempo_treino_opf = np.array([])
  all_tempo_teste_opf = np.array([])
  all_f1_opf = np.array([])

  all_acc_opf_svm = np.array([])
  all_acc_svm = np.array([])
  all_tempo_treino_svm = np.array([])
  all_tempo_teste_svm = np.array([])
  all_f1_svm = np.array([])

  all_acc_opf_knn =np.array([])
  all_acc_knn = np.array([])
  all_tempo_treino_knn = np.array([])
  all_tempo_teste_knn = np.array([])
  all_f1_knn = np.array([])


  #shuffle do dataset
  dataset = dataset.sample(frac=1, random_state=42)

  X,y,y_encoder = kdd_preprocessing(dataset)

  #variaveis auxiliares para as matrizes de confusao
  labels = np.unique(y)
  max_classes = len(labels)
  classes_names = np.unique(y)
  classes_names = y_encoder.inverse_transform(classes_names)


  train_folds_idx, test_folds_idx,folds = cria_folds(X)

  #matrizes de confusao
  cm_opf = np.zeros((max_classes, max_classes), dtype=int)
  cm_svm = np.zeros((max_classes, max_classes), dtype=int)
  cm_knn = np.zeros((max_classes, max_classes), dtype=int)


  #a cada run, os modelos sao treinados com um fold e testado com um fold (2*10 = 20)
  for run in range(10):
    print(f"\nExecução {run+1}")

    # selecao dos folds
    train_idx = folds[train_folds_idx[run]][1]
    test_idx  = folds[test_folds_idx[run]][1]

    X_train = X.iloc[train_idx].copy()
    y_train = y.iloc[train_idx].copy()
    X_test  = X.iloc[test_idx].copy()
    y_test  = y.iloc[test_idx].copy()

    #print(f"Tamanho treino: {len(X_train)}\nTamanho Teste:{len(X_test)}")
    X_train_np = X_train.values
    y_train_np = y_train.values
    X_test_np = X_test.values
    y_test_np = y_test.values

    #padronizacao dos dados
    standard_scaler = StandardScaler()
    X_train_np = standard_scaler.fit_transform(X_train_np)
    X_test_np = standard_scaler.transform(X_test_np)

    #pca = PCA(n_components=10)
    #X_train_np = pca.fit_transform(X_train_np)
    #X_test_np = pca.transform(X_test_np)

    opf = SupervisedOPF(distance="log_squared_euclidean", pre_computed_distance=None)

    K = cross_validation_knn(X_train_np,y_train_np,knn_cv_params)
    knn = KNeighborsClassifier(n_neighbors=K)

    C,gamma = cross_validation_svm(X_train_np,y_train_np,svm_cv_params)
    svm = SVC(kernel='rbf',C=C,gamma=gamma)


    t_train_opf = treinar(opf, "OPF", X_train_np, y_train_np)
    t_train_svm = treinar(svm, "SVM", X_train_np, y_train_np)
    t_train_knn = treinar(knn, "KNN", X_train_np, y_train_np)

    t_test_opf,preds_opf = testar(opf, "OPF", X_test_np)
    t_test_svm,preds_svm = testar(svm, "SVM", X_test_np)
    t_test_knn,preds_knn = testar(knn, "KNN", X_test_np)

    acc_opf_opf = opf_g.opf_accuracy(y_test_np, preds_opf)
    acc_opf = accuracy_score(y_test_np, preds_opf)
    f1_opf = f1_score(y_test_np, preds_opf,average='macro')

    acc_opf_svm = opf_g.opf_accuracy(y_test_np, preds_svm)
    acc_svm = accuracy_score(y_test_np, preds_svm)
    f1_svm = f1_score(y_test_np, preds_svm,average='macro')

    acc_opf_knn = opf_g.opf_accuracy(y_test_np, preds_knn)
    acc_knn = accuracy_score(y_test_np, preds_knn)
    f1_knn = f1_score(y_test_np, preds_knn,average='macro')

    all_acc_opf_opf = np.append(all_acc_opf_opf, acc_opf_opf)
    all_acc_opf = np.append(all_acc_opf, acc_opf)
    all_tempo_treino_opf = np.append(all_tempo_treino_opf, t_train_opf)
    all_tempo_teste_opf = np.append(all_tempo_teste_opf, t_test_opf)
    all_f1_opf = np.append(all_f1_opf,f1_opf)

    all_acc_opf_svm = np.append(all_acc_opf_svm, acc_opf_svm)
    all_acc_svm = np.append(all_acc_svm, acc_svm)
    all_tempo_treino_svm = np.append(all_tempo_treino_svm, t_train_svm)
    all_tempo_teste_svm = np.append(all_tempo_teste_svm, t_test_svm)
    all_f1_svm = np.append(all_f1_svm,f1_svm)

    all_acc_opf_knn = np.append(all_acc_opf_knn, acc_opf_knn)
    all_acc_knn = np.append(all_acc_knn, acc_knn)
    all_tempo_treino_knn = np.append(all_tempo_treino_knn, t_train_knn)
    all_tempo_teste_knn = np.append(all_tempo_teste_knn, t_test_knn)
    all_f1_knn = np.append(all_f1_knn,f1_knn)

    cm_svm += confusion_matrix(y_test_np,preds_svm,labels=labels)
    cm_opf += confusion_matrix(y_test_np,preds_opf,labels=labels)
    cm_knn += confusion_matrix(y_test_np,preds_knn,labels=labels)

  results = pd.DataFrame({
    "Modelos": ["OPF", "SVM", "KNN"],

    "Acc OPF-Style (mean)": [
        all_acc_opf_opf.mean(),
        all_acc_opf_svm.mean(),
        all_acc_opf_knn.mean()
    ],
    "Acc OPF-Style (std)": [
        all_acc_opf_opf.std(),
        all_acc_opf_svm.std(),
        all_acc_opf_knn.std()
    ],

    "Accuracy (mean)": [
        all_acc_opf.mean(),
        all_acc_svm.mean(),
        all_acc_knn.mean()
    ],
    "Accuracy (std)": [
        all_acc_opf.std(),
        all_acc_svm.std(),
        all_acc_knn.std()
    ],

    "F1 score (mean)": [
        all_f1_opf.mean(),
        all_f1_svm.mean(),
        all_f1_knn.mean()
    ],
    "F1 score (std)": [
        all_f1_opf.std(),
        all_f1_svm.std(),
        all_f1_knn.std()
    ],

    "Tempo Treino (mean)": [
        all_tempo_treino_opf.mean(),
        all_tempo_treino_svm.mean(),
        all_tempo_treino_knn.mean()
    ],
    "Tempo Treino (std)": [
        all_tempo_treino_opf.std(),
        all_tempo_treino_svm.std(),
        all_tempo_treino_knn.std()
    ],

    "Tempo Teste (mean)": [
        all_tempo_teste_opf.mean(),
        all_tempo_teste_svm.mean(),
        all_tempo_teste_knn.mean()
    ],
    "Tempo Teste (std)": [
        all_tempo_teste_opf.std(),
        all_tempo_teste_svm.std(),
        all_tempo_teste_knn.std()
    ]
    })

  matriz_de_confusao(cm_svm,classes_names,f"{dataset_name}/","SVM")
  matriz_de_confusao(cm_opf,classes_names,f"{dataset_name}/","OPF")
  matriz_de_confusao(cm_knn,classes_names,f"{dataset_name}/","KNN")
  results.to_csv(f"{dataset_name}/{dataset_name}.csv")


kdd_experiment(kddCup5,"KDDCUP-5")
kdd_experiment(kddCup10,"KDDCUP-10")
kdd_experiment(kddCup15,"KDDCUP-15")





